# -*- coding: utf-8 -*-
"""Day3 preprocessing

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V4ARRHBRV__tjnETc8UTMjQdb5G2Tup4

Preprocessing is a process of prparing the raww data and making it suitable for a machine learning model.It is the first and crucial step while creating a machine learning moadel

Steps involved:


1.  Getting the dataset
2.   Importing libraries
3.   Importing datasets
4.   Finding Missing data


ways to handle missing data
*   By deleting the particular row
*   By calculating the mean

5.Encoding categorial data(text to num)

*   one-Hot coding
*   Label


6.   Feature scaling(numeric to 0's & 1's)

*  MinMax Scaler = x-min/max-min
*  Standard  scaler = x-mean/std
      std = sqrt((x1-mean)*2 +(x2-mean)2 +(x3-mean)*2 )/n



7.   Splitting dataset into training and test set
"""

import pandas as pd
df = pd.read_csv('people_data.csv')
df.head()

from sklearn.preprocessing import LabelEncoder
data = ['Red','Green','Blue','Green','maggy','Cricket']
le = LabelEncoder()
encoded = le.fit_transform(data)
print(encoded)

data =pd.DataFrame({'color':['Red','Green','Blue','Green','Biscuit_color','White']})
encoded = pd.get_dummies(data, columns=['color'])
print(encoded)

from sklearn.preprocessing import MinMaxScaler

data = [[30],[60],[90]]
scaler = MinMaxScaler()
scaled = scaler.fit_transform(data)
print("MinMax scaled:",scaled)

from sklearn.preprocessing import StandardScaler

data = [[20],[50],[40]]
scaler = StandardScaler()
scaled = scaler.fit_transform(data)
print("Standard scaled:",scaled)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

data = pd.read_csv('people_data.csv')
print("Shape of data:",data.shape)
print("First 5 rows:\n",data.head())
print("\n")
data = data.dropna()
print(data)

plt.figure(figsize=(8,5))
plt.hist(data['Age'], bins = 10, color = 'green')
plt.title('Distribution of column')
plt.xlabel('Value')
plt.ylabel('Frequency')
plt.grid(True)
plt.show()

"""# Column transformer
---syntax: ('name' , transformer ,column_indices_or_names)

---name :Identitifier string for the transformer (any unique name)

---transformer : Any scikit-learn transformer(e.g, StandartdScaler(), OneHotEncoder())
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer


data = pd.read_csv('people_data.csv')
print("Shape of data:",data.shape)
print("First 5 rows:\n",data.head())
print("\n")

numeric_cols = ['Age']
transformer = ColumnTransformer([('impute_num', SimpleImputer(strategy='mean'), numeric_cols)] , remainder='passthrough')
data [numeric_cols] = transformer.fit_transform(data[numeric_cols])
print(data)

column_mean = np.mean(data['Age'])
print("mean of column:",column_mean)

"""fillna syntax:

data['column name'] = data['columnname'].fillna(value)
"""

import pandas as pd
from sklearn.preprocessing import LabelEncoder

data = pd.DataFrame({
    'Name':['Ram','Raj','Leo','Lia'],
    'City':['Indore','Mumbai',None,'Delhi'],
    'Age':[23,24,None,22]
})

print('Original Data:')
print(data)

data['Age'] = data['Age'].fillna(data['Age'].mean())          #filling numeric val
data['City'] = data['City'].fillna('UK')                      #filling alpha
print(data)

le = LabelEncoder()
data['City'] = le.fit_transform(data['City'])
print(data)

print("\nCleaned and Preprocessed Data")
print(data)
print("\n")
print(data['Age'])

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

dataset = pd.read_csv('Data.csv')
print(dataset)
x = dataset.iloc[:,:-1].values
y = dataset.iloc[:,-1].values

print("\n")
print("Original x:")
print(x)
print("\n")
print("Original y:")
print(y)

minutes = int (input('enter time in minutes'))
print(f'{minutes} minutes= {minutes*60} seconds')